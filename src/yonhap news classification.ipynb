{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('yonhap_ready_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>article_len</th>\n",
       "      <th>sec1</th>\n",
       "      <th>sec_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'회장이 청부폭력' 루머 협박범도 기소…사이버명예훼손 전담수사 첫 사례 ...</td>\n",
       "      <td>\"해경이 가만있으라 방송\" 허위사실 유포 40대 기소</td>\n",
       "      <td>966</td>\n",
       "      <td>사회</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>지난 해 9월 북한의 함경북도 항구도시 나진과 러시아 극동지역 도시 ...</td>\n",
       "      <td>南 점검단 방북…나진-하산 프로젝트 시범운송 시작(종합)</td>\n",
       "      <td>1539</td>\n",
       "      <td>정치</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>포항 도착한 화물선       러시아 시베리아산 유연탄 4만 500t을...</td>\n",
       "      <td>나진-하산 프로젝트 탄력…시범수송 석탄 포항 도착(종합)</td>\n",
       "      <td>1827</td>\n",
       "      <td>경제</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0        '회장이 청부폭력' 루머 협박범도 기소…사이버명예훼손 전담수사 첫 사례 ...   \n",
       "1          지난 해 9월 북한의 함경북도 항구도시 나진과 러시아 극동지역 도시 ...   \n",
       "2         포항 도착한 화물선       러시아 시베리아산 유연탄 4만 500t을...   \n",
       "\n",
       "                             title  article_len sec1  sec_idx  \n",
       "0    \"해경이 가만있으라 방송\" 허위사실 유포 40대 기소          966   사회        4  \n",
       "1  南 점검단 방북…나진-하산 프로젝트 시범운송 시작(종합)         1539   정치        6  \n",
       "2  나진-하산 프로젝트 탄력…시범수송 석탄 포항 도착(종합)         1827   경제        0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443312,)\n",
      "(443312,)\n"
     ]
    }
   ],
   "source": [
    "X = df.article\n",
    "y = df.sec_idx\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376815,)\n",
      "(66497,)\n",
      "(376815,)\n",
      "(66497,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from konlpy.tag import Mecab; m = Mecab()\n",
    "#pos = lambda d: ['/'.join(p) for p in m.pos(d)]\n",
    "def noun_tagger(text):\n",
    "    #return [pos[0] for pos in m.pos(text) if (pos[1] in ['SL','SH','SN']) or pos[1].startswith('NN')]\n",
    "    return [pos[0] for pos in m.pos(text) if pos[1].startswith('NN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "    * vect.fit(train) learns the vocabulary of the training data\n",
    "    * vect.transform(train) uses the fitted vocabulary to build a document term matrix from the training data\n",
    "    * vect.transform(test) uses the fitted vocabulary to build a document term matrix from the testing data(and ignores tokens it hasn't seen before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_news=['지난해', '중','말', '뒤', '곳', '군', '위', '개', '간', '건', '이날', '도', '등', '명', '시', '앞', '원', '분', '회', '년', '것', '씨', '일', '월','오전','오후']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 40s, sys: 18.2 s, total: 26min 58s\n",
      "Wall time: 26min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(sublinear_tf=True, tokenizer=noun_tagger,stop_words=stopwords_news, ngram_range=(1,3), min_df=5, max_df=.5)\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376815, 2473920)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66497, 2473920)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save vector & dtm\n",
    "\n",
    "https://stackoverflow.com/questions/29788047/keep-tfidf-result-for-predicting-new-content-using-scikit-for-python\n",
    "https://stackoverflow.com/questions/32764991/how-do-i-store-a-tfidfvectorizer-for-future-use-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"yonhap_tfidf_vect.pkl\", 'wb') as handle:\n",
    "    pickle.dump(vect, handle)\n",
    "\n",
    "with open(\"yonhap_dtm.pkl\", 'wb') as handle:\n",
    "    pickle.dump(X_test_dtm, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.56 s, sys: 284 ms, total: 3.84 s\n",
      "Wall time: 3.85 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87316721055085189"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         경제       0.94      0.90      0.92     16783\n",
      "         과학       0.48      0.79      0.60       371\n",
      "         국제       0.83      0.94      0.88     12136\n",
      "         문화       0.77      0.90      0.83      3665\n",
      "         사회       0.88      0.83      0.85     17451\n",
      "         생활       0.51      0.76      0.61      1256\n",
      "         정치       0.92      0.85      0.88     14835\n",
      "\n",
      "avg / total       0.88      0.87      0.88     66497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_class, target_names=['경제', '과학', '국제', '문화', '사회', '생활', '정치']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice Multinomial NB can be better than Linear SVM in some situations and svm better than NB on other datasets. Apparently t's possible to combine the two approaches to get a very good baseline: projects:nbsvm - Sida I. Wang\n",
    "\n",
    "You can also try non-linear SVMs but often the quadratic complexity of the SMO algorithm (for instance as implemented in libsvm) makes it not practical on datasets with more than 5000 documents. Instead on prefer to use liblinear than can only train linear SVM on large datasets.\n",
    "\n",
    "https://www.quora.com/What-are-the-differences-similarities-between-SVM-Naive-Bayes-for-binary-text-classification-wrt-how-they-are-processing-the-features\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "#clf = svm.SVC(decision_function_shape='ovo')\n",
    "clfrSVM=svm.LinearSVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 624 ms, total: 1min 40s\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clfrSVM.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_class_svm = clfrSVM.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92479359971126518"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         경제       0.97      0.94      0.95     16783\n",
      "         과학       0.79      0.65      0.72       371\n",
      "         국제       0.89      0.99      0.94     12136\n",
      "         문화       0.90      0.88      0.89      3665\n",
      "         사회       0.90      0.91      0.91     17451\n",
      "         생활       0.81      0.63      0.71      1256\n",
      "         정치       0.95      0.91      0.93     14835\n",
      "\n",
      "avg / total       0.93      0.92      0.92     66497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_class_svm, target_names=['경제', '과학', '국제', '문화', '사회', '생활', '정치']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/40115043/no-space-left-on-device-error-while-fitting-sklearn-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([297,  52,   0,  76, 197,  55, 110])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "counts = np.bincount(y_pred_class[(y_pred_class!=2) & (y_test==2)])\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134870           아시아인프라투자은행(AIIB) 개소식에서 연설하는 리커창 중국 총리  ...\n",
       "184399              1년만에 만장일치 결정 \"노동시장 호조·물가상승 고려한 조치, 경...\n",
       "314134           국제유가는 10일(현지시간) 비교적 큰 폭의 오름세를 보였다.     ...\n",
       "31614            중국인, 미국 내 외국인 주택 거래 '큰손'으로       지난해 미국...\n",
       "196063           런던 남동부의 주택가   \"세 사는 가구 늘고 임차료도 올라 저축은커녕...\n",
       "129654           한적한 중국 베이징의 한 백화점       중국의 지난해 재정수입 증가...\n",
       "406737          스마트폰에 엇갈린 희비…대만은 작년 아이폰7 덕에 GDP 깜짝 성장   ...\n",
       "217240           일본 주식 시장   외국인투자 증가 주요인…25년 연속 세계 최대 채권...\n",
       "176502           중국 창업의 산실 중관춘［EPA=연합뉴스 자료사진］       중국에서...\n",
       "196248                  영국의 유럽연합(EU) 이탈(브렉시트·Brexit) 결정 ...\n",
       "99105                유럽 주요 증시는 18일(현지시간) 상승세로 출발했다.     ...\n",
       "443258          \"韓기업들 중국인 기호와 환경 적응 못해 경쟁력 상실\" 주장  사드 보복...\n",
       "261208           중국 저장성 항저우   홍콩 부동산 거래량 6개월간 39% 급감…25년...\n",
       "301044           456억달러로 2015년과 비교해 두 배 늘어   중국의 대(對)미국 ...\n",
       "91051           FT \"1월 양적완화 발표로 금융시장 분위기 급반전\"       '유로존...\n",
       "298385            러시아가 우크라이나 사태 등을 둘러싼 서방과의 갈등으로 대다수 서방국...\n",
       "111006           리커창 중국 총리.   \"기본토대 개선·거대 잠재력 유지\"…'하반기 총...\n",
       "236026           스위스 바젤 소재 신젠타 본사       중국 국유기업인 중국화공(中國...\n",
       "203314           베트남 하노이 시내 도로  현대·기아차 현지 생산 확대…소형차 시장 공...\n",
       "389270         중국인들에게 인기 많은 한국 화장품       지난해 중국이 수입을 불허한...\n",
       "127365           \"중국 올해 경제성장률 6.5~7% 예상\"      = 중국의 경제학자...\n",
       "442794           경기 악화시 채권 매입 확대 입장 유지   유럽중앙은행(ECB)이 제로...\n",
       "206454           애플사 아이폰들        러시아 당국이 아이폰 생산업체 애플을 상대...\n",
       "92350                유럽중앙은행(ECB)은 5일 통화정책위원회 회의를 열어 기준금리...\n",
       "399491           중국 장화이 자동차 조립 라인 전경   중국 토종 업체 장화이자동차(J...\n",
       "338584         인도네시아서 판매중단된 한국라면 4종 지난 18일 인도네시아 식품의약청이 ...\n",
       "254817           일본 도쿄 우에노공원의 벚꽃  1~2월 누계는 한국인이 100만5천70...\n",
       "127285               유럽증시가 하락세를 지속하고 있다. 뉴욕증시와 유가의 약세가 영...\n",
       "345660           일본 정부가 정원 미달이 이어지는 사립대에 보조금 지원을 줄이고 심각할...\n",
       "55380                변동환율제 시행으로 가치가 폭락했던 카자흐스탄의 텡게화가 21일...\n",
       "                                ...                        \n",
       "338549         사우디 국기   사우디아라비아 유력 투자사 자와드인베스트먼트는 19일(현지...\n",
       "236484                  대만 전자업체 폭스콘(홍하이)이 일본 전자업체 샤프를 매수...\n",
       "351696          저임금 노동인구 감소도 영향 미쳐  고속철에서 라면을 먹는 한 중국인홍콩...\n",
       "405055           영국 대형 슈퍼마켓 테스코가 이익전망치를 부풀린 혐의를 인정하고 1억2...\n",
       "84378                독일 북부 지역에 있는 독일기업과 한국기업 간 협력 촉진을 목적...\n",
       "135637                  영국 석유회사 BP는 12일(현지시간) 국제유가 급락에 따...\n",
       "130243                  이탈리아 자동차업체인 피아트 크라이슬러(FCA)가 지난해 ...\n",
       "314268           캐나다의 대형 백화점 체인인 시어스캐나다가 경영난을 벗어날 회생안 마련...\n",
       "321766          약 3천598억원 규모…만기는 100년 예상   영국의 명문 옥스퍼드대학...\n",
       "244062              [편집자 주] 본고는 자료 제공사에서 제공한 것으로, 연합뉴스는 ...\n",
       "341418           유럽중앙은행(ECB)은 8일(이하 현지시간) 에스토니아 탈린에서 정례 ...\n",
       "404242          -- 순자산, 2016년 1,756억 달러(USD)로 증가      --...\n",
       "397728            수년 동안 급등세를 지속하던 캐나다 밴쿠버의 지난달 주택 거래가 1년...\n",
       "328537          -- 주요 지수 공급업체로는 최초      -- MVIS(R) 지수, 투...\n",
       "206892               미국 유통업체인 월마트가 신생 온라인 유통업체 제트닷컴(Jet....\n",
       "301390            인도의 제조업 경기가 시중에 유통되는 현금의 86%를 차지하던 500...\n",
       "237176                  태국 국가경제사회개발위원회(NESDB)는 15일 4분기 국...\n",
       "5808              일본은행        마리오 드라기 유럽중앙은행(ECB) 총재의 추가...\n",
       "208413           英 중앙은행 총재        영국 중앙은행인 영란은행(BOE)이 4일...\n",
       "18655                   세계 성장 엔진인 중국의 현재 모습이 과거 일본의 '잃어버...\n",
       "270018           일본 나리타국제공항 입국자 게이트 주변이 각국에서 찾아온 여행객으로 붐...\n",
       "256087           아베 총리, 도쿄서 동일본대지진 5주기 기자회견(  정부 교부금·피해배...\n",
       "192958           유로존 인플레 제고 등으로 경제활력 증진 기대   유럽중앙은행(ECB)...\n",
       "397405            일본의 장기금리가 3일 한때 0.150%로 1년만에 최고수준을 기록했...\n",
       "19385            19일 인도 라자스탄 주 자이푸르에서 손윤호(오른쪽) HM디지털 대표이...\n",
       "52618              \"성장엔진에서 문제아 전락\" 서방언론 지적에 공세나서        ...\n",
       "222295              * 1분기 특기 사항:      - 현금 EBITDA는 1,950...\n",
       "275135                  중국 국책 연구기관이 이례적으로 국가부채의 위험성을 경고하...\n",
       "46448            \"중국 정년연장 추진，노령화·연금고갈 대비\"     = 중국 정부가 최...\n",
       "149282           기준금리 0.5% 유지…\"주택 시장 둔화·수출 부진\"   캐나다 중앙은...\n",
       "Name: article, Length: 297, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[(y_pred_class==0) & (y_test==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>article_len</th>\n",
       "      <th>sec1</th>\n",
       "      <th>sec_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149282</th>\n",
       "      <td>기준금리 0.5% 유지…\"주택 시장 둔화·수출 부진\"   캐나다 중앙은...</td>\n",
       "      <td>캐나다 중앙은행, 올 성장률 전망 1.1%로 낮춰</td>\n",
       "      <td>899</td>\n",
       "      <td>국제</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  article  \\\n",
       "149282         기준금리 0.5% 유지…\"주택 시장 둔화·수출 부진\"   캐나다 중앙은...   \n",
       "\n",
       "                              title  article_len sec1  sec_idx  \n",
       "149282  캐나다 중앙은행, 올 성장률 전망 1.1%로 낮춰          899   국제        2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index==149282]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"yonhap_svm_clf.pkl\", 'wb') as handle:\n",
    "    pickle.dump(clfrSVM, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"yonhap_nb_clf.pkl\", 'wb') as handle:\n",
    "    pickle.dump(nb, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

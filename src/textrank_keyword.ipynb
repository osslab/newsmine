{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab; t = Mecab()\n",
    "#tags_ko = t.pos(\"문재인 대통령이 18일 \\'돈 봉투 만찬사건\\'의 당사자인 이영렬 서울중앙지검장과 안태근 법무부 검찰국장의 사표를 즉각 수리하지 않기로 사실상 방침을 세운 것은 검찰개혁 및 공직기강 확립 의지에 따른 것으로 분석된다. 청와대 고위관계자는 이 지검장과 안 국장이 이날 사의를 표명한 데 대해 \\\"규정상 감찰 중에는 사의 수리가 안 된다\\\"는 입장을 명확히 함으로써 당사자의 사표를 받는 선에서 문제를 정리하지 않고 끝까지 진상 규명을 하겠다는 뜻을 분명히 했다. 문 대통령의 5·18 민주화운동 기념식 참석 때문에 조국 민정수석은 이 지검장과 안 국장의 사의 표명을 이날 오후 문 대통령에게 정식 보고할 예정이지만, 문 대통령 역시 규정에 따른 업무 처리를 강조할 것으로 전망된다.\")\n",
    "#tags_ko = t.pos(\"\\\"5 ·18 헌법 전문 수록과 개헌 논의는 별도\\\" 청와대는 18일 새 정부에 \\'참여정부\\'나 \\'국민의 정부\\' 같은 별도의 명칭을 정하지 않기로 했다. 청와대 관계자는 18일 춘추관에서 기자들과 만나 \\\"참여정부나 국민의정부처럼 지칭할 계획은 없다\\\"며 \\\"실용적으로 사용하겠다\\\"고 말했다. 이어 \\\"언론도 더불어민주당 정부라고 하실 수도, 문재인 정부라고 하실 수도 있을 것\\\"이라며 \\\"자율적으로, 실용적으로 사용해달라\\\"고 말했다. 문재인 대통령은 취임 직후 당을 존중하는 차원에서 \\'더불어민주당 정부\\'로 불러달라고 했으나, 이날 37주년 5 ·18 광주민주화운동 기념사에선 \\'문재인 정부\\'를 두 차례 언급했다. 이를 두고 일각에선 새 정부의 명칭이 \\'문재인 정부\\'로 정해진 것이 아니냐는 추측이 제기됐다. 이 관계자는 또 문 대통령이 기념사에서 5 ·18 민주화운동 정신의 헌법 전문 수록 공약을 재확인하며 국회와 국민에 개헌 협조를 요청한 데 대해 \\\"5 ·18 정신을 헌법 전문에 담겠다는 공약은 개헌 논의와는 별도 트랙\\\"이라며 \\\"청와대발로 개헌안을 던지는 그런 해석은 맞지 않다\\\"고 설명했다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/davidadamojr/TextRank/blob/master/textrank/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter; t = Twitter()\n",
    "#tags_ko = t.pos(\"문재인 대통령이 18일 \\'돈 봉투 만찬사건\\'의 당사자인 이영렬 서울중앙지검장과 안태근 법무부 검찰국장의 사표를 즉각 수리하지 않기로 사실상 방침을 세운 것은 검찰개혁 및 공직기강 확립 의지에 따른 것으로 분석된다. 청와대 고위관계자는 이 지검장과 안 국장이 이날 사의를 표명한 데 대해 \\\"규정상 감찰 중에는 사의 수리가 안 된다\\\"는 입장을 명확히 함으로써 당사자의 사표를 받는 선에서 문제를 정리하지 않고 끝까지 진상 규명을 하겠다는 뜻을 분명히 했다. 문 대통령의 5·18 민주화운동 기념식 참석 때문에 조국 민정수석은 이 지검장과 안 국장의 사의 표명을 이날 오후 문 대통령에게 정식 보고할 예정이지만, 문 대통령 역시 규정에 따른 업무 처리를 강조할 것으로 전망된다.\")\n",
    "text = \"\\\"5 ·18 헌법 전문 수록과 개헌 논의는 별도\\\" 청와대는 18일 새 정부에 \\'참여정부\\'나 \\'국민의 정부\\' 같은 별도의 명칭을 정하지 않기로 했다. 청와대 관계자는 18일 춘추관에서 기자들과 만나 \\\"참여정부나 국민의정부처럼 지칭할 계획은 없다\\\"며 \\\"실용적으로 사용하겠다\\\"고 말했다. 이어 \\\"언론도 더불어민주당 정부라고 하실 수도, 문재인 정부라고 하실 수도 있을 것\\\"이라며 \\\"자율적으로, 실용적으로 사용해달라\\\"고 말했다. 문재인 대통령은 취임 직후 당을 존중하는 차원에서 \\'더불어민주당 정부\\'로 불러달라고 했으나, 이날 37주년 5 ·18 광주민주화운동 기념사에선 \\'문재인 정부\\'를 두 차례 언급했다. 이를 두고 일각에선 새 정부의 명칭이 \\'문재인 정부\\'로 정해진 것이 아니냐는 추측이 제기됐다. 이 관계자는 또 문 대통령이 기념사에서 5 ·18 민주화운동 정신의 헌법 전문 수록 공약을 재확인하며 국회와 국민에 개헌 협조를 요청한 데 대해 \\\"5 ·18 정신을 헌법 전문에 담겠다는 공약은 개헌 논의와는 별도 트랙\\\"이라며 \\\"청와대발로 개헌안을 던지는 그런 해석은 맞지 않다\\\"고 설명했다.\"\n",
    "tags_ko = t.pos(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "textlist = [x[0] for x in tags_ko]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#def filter_for_tags(tagged, tags=['NNP','NNG']):\n",
    "def filter_for_tags(tagged, tags=['Noun','Adjective']):\n",
    "    \"\"\"Apply syntactic filters based on POS tags.\"\"\"\n",
    "    return [item for item in tagged if item[1] in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tags_ko = filter_for_tags(tags_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize(tagged):\n",
    "    \"\"\"Return a list of tuples with the first item's periods removed.\"\"\"\n",
    "    return [(item[0].replace('.', ''), item[1]) for item in tagged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tags_ko = normalize(tags_ko)\n",
    "\n",
    "#set_list=list(set([x[0] for x in tags_ko]))\n",
    "\n",
    "#word_set_list = list(tags_ko)\n",
    "set_list=list([x[0] for x in tags_ko])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "from gensim.summarization.commons import build_graph as _build_graph\n",
    "from gensim.summarization.commons import remove_unreachable_nodes as _remove_unreachable_nodes\n",
    "from gensim.summarization.pagerank_weighted import pagerank_weighted as _pagerank\n",
    "from gensim.summarization.keywords import _set_graph_edges\n",
    "\n",
    "def build_graph(nodes):\n",
    "    \"\"\"Return a networkx graph instance.\n",
    "    :param nodes: List of hashables that represent the nodes of a graph.\n",
    "    \"\"\"\n",
    "    #gr = nx.Graph()  # initialize an undirected graph\n",
    "    #gr.add_nodes_from(nodes)\n",
    "    graph = _build_graph(nodes)\n",
    "    \n",
    "    '''\n",
    "    nodePairs = list(itertools.combinations(nodes, 2))\n",
    "\n",
    "    # add edges to the graph (weighted by Levenshtein distance)\n",
    "    for pair in nodePairs:\n",
    "        firstString = pair[0]\n",
    "        secondString = pair[1]\n",
    "        #levDistance = levenshtein_distance(firstString, secondString)\n",
    "        #gr.add_edge(firstString, secondString, weight=levDistance)\n",
    "        edge = (firstString, secondString)\n",
    "        #print(edge)\n",
    "        if graph.has_node(firstString) and graph.has_node(secondString) and not graph.has_edge(edge):\n",
    "            graph.add_edge(edge)\n",
    "    '''\n",
    "    return graph\n",
    "\n",
    "def levenshtein_distance(first, second):\n",
    "    \"\"\"Return the Levenshtein distance between two strings.\n",
    "    Based on:\n",
    "        http://rosettacode.org/wiki/Levenshtein_distance#Python\n",
    "    \"\"\"\n",
    "    if len(first) > len(second):\n",
    "        first, second = second, first\n",
    "    distances = range(len(first) + 1)\n",
    "    for index2, char2 in enumerate(second):\n",
    "        new_distances = [index2 + 1]\n",
    "        for index1, char1 in enumerate(first):\n",
    "            if char1 == char2:\n",
    "                new_distances.append(distances[index1])\n",
    "            else:\n",
    "                new_distances.append(1 + min((distances[index1],\n",
    "                                             distances[index1 + 1],\n",
    "                                             new_distances[-1])))\n",
    "        distances = new_distances\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d2f8b4448df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0m_set_graph_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0m_remove_unreachable_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/gensim/summarization/keywords.py\u001b[0m in \u001b[0;36m_set_graph_edges\u001b[0;34m(graph, tokens, split_text)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_set_graph_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0m_process_first_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0m_process_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/gensim/summarization/keywords.py\u001b[0m in \u001b[0;36m_process_text\u001b[0;34m(graph, tokens, split_text)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWINDOW_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0m_process_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0m_update_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/gensim/summarization/keywords.py\u001b[0m in \u001b[0;36m_process_word\u001b[0;34m(graph, tokens, queue, word)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_process_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword_to_compare\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_queue_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0m_set_graph_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_compare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/gensim/summarization/keywords.py\u001b[0m in \u001b[0;36m_set_graph_edge\u001b[0;34m(graph, tokens, word_a, word_b)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_set_graph_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_a\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mlemma_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mlemma_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0medge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlemma_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemma_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "#calculated_page_rank = nx.pagerank(graph, weight='weight')\n",
    "\n",
    "# most important words in ascending order of importance\n",
    "#keyphrases = sorted(calculated_page_rank, key=calculated_page_rank.get,reverse=True)\n",
    "\n",
    "graph = build_graph(set_list)\n",
    "_set_graph_edges(graph, set_list, textlist)\n",
    "_remove_unreachable_nodes(graph)\n",
    "    \n",
    "pagerank_scores = _pagerank(graph)\n",
    "print(pagerank_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_set_graph_edges 를 tokes[\"워드명\"].token에 맞춰서 만들어야 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['논의', '운동', '관계자', '헌법', '일', '청와대', '기념', '민주당', '실용', '개헌', '문재인', '로', '수록', '정부', '명칭', '사', '라며', '고', '전문', '참여정부', '별도', '정신', '국민', '새', '것', '수도', '대통령', '민주화', '공약', '추측', '달라', '기자', '를', '해석', '직후', '또', '춘추관', '일각', '이', '정해진', '국회', '언론', '주년', '발', '없다', '차례', '당', '재', '있', '자율', '같은', '개헌안', '트랙', '날', '아니냐', '지칭', '협조', '데', '제기', '대해', '계획', '그런', '차원', '두', '사용', '나', '며', '취임', '문', '국민의정부', '광주', '언급']\n"
     ]
    }
   ],
   "source": [
    "nodes = graph.nodes()\n",
    "\n",
    "nodes.sort(key=lambda s: pagerank_scores[s], reverse=True)\n",
    "#for node in nodes:\n",
    "#    print(pagerank_scores[node])\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "    one_third = len(set_list) // 3\n",
    "    keyphrases = keyphrases[0:one_third + 1]\n",
    "\n",
    "    # take keyphrases with multiple words into consideration as done in the\n",
    "    # paper - if two words are adjacent in the text and are selected as\n",
    "    # keywords, join them together\n",
    "    modified_key_phrases = set([])\n",
    "    # keeps track of individual keywords that have been joined to form a\n",
    "    # keyphrase\n",
    "    dealt_with = set([])\n",
    "    i = 0\n",
    "    j = 1\n",
    "    while j < len(textlist):\n",
    "        first = textlist[i]\n",
    "        second = textlist[j]\n",
    "        if first in keyphrases and second in keyphrases:\n",
    "            keyphrase = first + ' ' + second\n",
    "            modified_key_phrases.add(keyphrase)\n",
    "            dealt_with.add(first)\n",
    "            dealt_with.add(second)\n",
    "        else:\n",
    "            if first in keyphrases and first not in dealt_with:\n",
    "                modified_key_phrases.add(first)\n",
    "\n",
    "            # if this is the last word in the text, and it is a keyword, it\n",
    "            # definitely has no chance of being a keyphrase at this point\n",
    "            if j == len(textlist) - 1 and second in keyphrases and \\\n",
    "                    second not in dealt_with:\n",
    "                modified_key_phrases.add(second)\n",
    "\n",
    "        i = i + 1\n",
    "        j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['방침', '개혁', '당사자', '확립', '고위 관계자', '중앙지', '이영렬', '봉투 만찬', '보고', '안태근 법무부', '강조', '공직', '전망', '문재인 대통령', '청와대 고위', '운동 기념식']\n"
     ]
    }
   ],
   "source": [
    "print(list(modified_key_phrases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대통령',\n",
       " '청와대',\n",
       " '관계자',\n",
       " '이영렬',\n",
       " '법무부',\n",
       " '중앙지',\n",
       " '안태근',\n",
       " '기념식',\n",
       " '문재인',\n",
       " '당사자',\n",
       " '공직',\n",
       " '방침',\n",
       " '확립',\n",
       " '만찬',\n",
       " '전망',\n",
       " '봉투',\n",
       " '개혁',\n",
       " '강조',\n",
       " '고위',\n",
       " '운동',\n",
       " '보고']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'감찰': 0.01569353131118335,\n",
       " '강조': 0.015797287805814325,\n",
       " '개혁': 0.015797287805814325,\n",
       " '검장': 0.01538105663309433,\n",
       " '검찰': 0.015589655723020039,\n",
       " '고위': 0.015797287805814325,\n",
       " '공직': 0.015797287805814325,\n",
       " '관계자': 0.02089075101670032,\n",
       " '국장': 0.015484702649857874,\n",
       " '규명': 0.01558976853536536,\n",
       " '규정': 0.015485887790184876,\n",
       " '기강': 0.01569774213112877,\n",
       " '기념식': 0.02078315258230089,\n",
       " '끝': 0.015065379603418456,\n",
       " '당사자': 0.0203697340307412,\n",
       " '대통령': 0.02099050941422518,\n",
       " '돈': 0.01506537960341846,\n",
       " '뜻': 0.01506537960341846,\n",
       " '만찬': 0.015797287805814325,\n",
       " '문': 0.014862288524281194,\n",
       " '문재인': 0.02078220765111847,\n",
       " '문제': 0.015593122561869791,\n",
       " '민정': 0.015486006352589558,\n",
       " '민주': 0.01569341168121754,\n",
       " '방침': 0.015797287805814325,\n",
       " '법무부': 0.02088688974636447,\n",
       " '보고': 0.01579728780581432,\n",
       " '봉투': 0.015797287805814325,\n",
       " '분석': 0.015589652379133675,\n",
       " '사': 0.014549559767666274,\n",
       " '사건': 0.015280038606936936,\n",
       " '사실': 0.015280038606936936,\n",
       " '사의': 0.015280038606936937,\n",
       " '사표': 0.015280038606936937,\n",
       " '서울': 0.01579728780581432,\n",
       " '선': 0.01506537960341846,\n",
       " '수리': 0.015485770673029134,\n",
       " '수석': 0.015485889396963652,\n",
       " '안': 0.014966029371227233,\n",
       " '안태근': 0.020886070800458678,\n",
       " '업무': 0.015697803125368264,\n",
       " '예정': 0.015589532794221195,\n",
       " '오후': 0.01579728780581432,\n",
       " '운동': 0.01579728780581432,\n",
       " '의지': 0.01569780312536826,\n",
       " '이날': 0.015697803125368264,\n",
       " '이영렬': 0.02088688974636447,\n",
       " '입장': 0.015484702649857872,\n",
       " '장': 0.014753956492029699,\n",
       " '전망': 0.015797287805814325,\n",
       " '정리': 0.01548586117072448,\n",
       " '정식': 0.01559386282886825,\n",
       " '조국': 0.01579728780581432,\n",
       " '중앙지': 0.020886889746364462,\n",
       " '지검': 0.01579728780581432,\n",
       " '진상': 0.01579728780581432,\n",
       " '참석': 0.015589652379133675,\n",
       " '처리': 0.015589534463313948,\n",
       " '청와대': 0.02099050941422518,\n",
       " '표명': 0.01569353048061971,\n",
       " '확립': 0.015797287805814325}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculated_page_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from konlpy.tag import Twitter; twitter = Twitter()\n",
    "sentences=[\"문재인 대통령 여론조사 결과\", \"문재인 결과 나빠\"]\n",
    "bow1 = Counter(twitter.nouns(sentences[0]))\n",
    "# Counter({'미쿠': 2})\n",
    "bow2 = Counter(twitter.nouns(sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'결과': 1, '대통령': 1, '문재인': 1, '여론조사': 1})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'결과': 1, '문재인': 1})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_index = sum((bow1 & bow2).values()) / sum((bow1 | bow2).values())\n",
    "j_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7f418ba74550>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = nx.Graph()\n",
    "graph.add_nodes_from(sentences)\n",
    "graph.add_edge(sentences[0], sentences[1], weight=j_index)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pagerank = nx.pagerank(graph, weight='weight')\n",
    "reordered = sorted(pagerank, key=pagerank.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['문재인 결과 나빠', '문재인 대통령 여론조사 결과']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
